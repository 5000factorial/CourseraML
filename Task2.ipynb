{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Apps\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "E:\\Apps\\Anaconda\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "features = pd.read_csv('./features.csv', index_col='match_id')\n",
    "\n",
    "X = features.loc[:,'start_time':'dire_first_ward_time'] \n",
    "y_all = features.loc[:,'duration':'barracks_status_dire']\n",
    "\n",
    "num = X.count().to_frame()\n",
    "X = StandardScaler().fit_transform(X.fillna(0)) #замена пропусков на 0 и масштабирование\n",
    "y = y_all.loc[:,'radiant_win'] #целевая переменная -- 'radiant_win'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Оцените качество логистической регрессии (sklearn.linear_model.LogisticRegression с L2-регуляризацией) с помощью кросс-валидации по той же схеме, которая использовалась для градиентного бустинга. Подберите при этом лучший параметр регуляризации (C). Какое наилучшее качество у вас получилось? Как оно соотносится с качеством градиентного бустинга? Чем вы можете объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "При C = 1e-05 качество = 0.6951179312487861, затраченное время: 0:00:01.772970\n",
      "При C = 0.0001 качество = 0.7111806156556447, затраченное время: 0:00:01.921383\n",
      "При C = 0.001 качество = 0.7161807344475418, затраченное время: 0:00:02.890072\n",
      "При C = 0.01 качество = 0.7162375194444629, затраченное время: 0:00:03.878756\n",
      "При C = 0.1 качество = 0.7163777898535342, затраченное время: 0:00:03.992718\n",
      "При C = 1 качество = 0.7163069190006354, затраченное время: 0:00:04.092686\n",
      "При C = 10 качество = 0.7162376718379526, затраченное время: 0:00:04.153667\n",
      "При C = 100 качество = 0.7162880809351589, затраченное время: 0:00:04.001716\n",
      "При C = 1000 качество = 0.7163918109388765, затраченное время: 0:00:03.872757\n",
      "При C = 10000 качество = 0.7163161802400861, затраченное время: 0:00:04.075693\n",
      "Лучший результат: 0.7163918109388765 при С = 1000\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle = True) #генератор разбиений для кросс-валидации по 5 блокам\n",
    "cpow = range(-5,5)\n",
    "C = []\n",
    "score = []\n",
    "for i in cpow:\n",
    "    C.append(10 ** i)\n",
    "for c in C:\n",
    "    start_time = datetime.datetime.now()\n",
    "    clf = LogisticRegression(penalty='l2', solver = 'lbfgs', C = c)\n",
    "    res = np.mean(cross_val_score(clf, X, y, cv = kf, scoring = 'roc_auc'))\n",
    "    score.append(res)\n",
    "    print('При C = ' + str(c) + ' качество = ' + str(res) + ', затраченное время: ' + str(datetime.datetime.now() - start_time))\n",
    "maxscore = max(score)\n",
    "maxscorei = score.index(maxscore)\n",
    "print('Лучший результат: ' + str(maxscore) + ' при С = ' + str(C[maxscorei]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наибольшее значение метрики AUC-ROC(0.71607) получилось при C = 0.01. Этот показатель выше чем при использовании градиентного бустинга(AUC-ROC = 0.6896).\n",
    "Логистическая регрессия работает в ~10 раз быстрее градиентного бустинга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Среди признаков в выборке есть категориальные, которые мы использовали как числовые, что вряд ли является хорошей идеей. Категориальных признаков в этой задаче одиннадцать: lobby_type и r1_hero, r2_hero, ..., r5_hero, d1_hero, d2_hero, ..., d5_hero. Уберите их из выборки, и проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. Изменилось ли качество? Чем вы можете это объяснить?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Apps\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "E:\\Apps\\Anaconda\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "X = features.loc[:,'start_time':'dire_first_ward_time'] \n",
    "columns = ['lobby_type','r1_hero','r2_hero','r3_hero','r4_hero','r5_hero','d1_hero','d2_hero','d3_hero','d4_hero','d5_hero']\n",
    "X.drop(columns, inplace=True, axis=1)\n",
    "X = StandardScaler().fit_transform(X.fillna(0)) #замена пропусков на 0 и масштабирование\n",
    "X_heroes = features.loc[:,columns] \n",
    "X_heroes.drop('lobby_type', inplace=True, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "При C = 1e-05 качество = 0.6950639641619949, затраченное время: 0:00:01.770431\n",
      "При C = 0.0001 качество = 0.7113744525046666, затраченное время: 0:00:02.077334\n",
      "При C = 0.001 качество = 0.7160444589202042, затраченное время: 0:00:03.179996\n",
      "При C = 0.01 качество = 0.7163189711449724, затраченное время: 0:00:04.640495\n",
      "При C = 0.1 качество = 0.7166367864368306, затраченное время: 0:00:06.049565\n",
      "При C = 1 качество = 0.7164097550101586, затраченное время: 0:00:04.742900\n",
      "При C = 10 качество = 0.7164453487813383, затраченное время: 0:00:04.480561\n",
      "При C = 100 качество = 0.7164078546893528, затраченное время: 0:00:03.841768\n",
      "При C = 1000 качество = 0.7164350762379791, затраченное время: 0:00:04.571533\n",
      "При C = 10000 качество = 0.7161762469961173, затраченное время: 0:00:05.623195\n",
      "Лучший результат: 0.7166367864368306 при С = 0.1\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle = True) #генератор разбиений для кросс-валидации по 5 блокам\n",
    "cpow = range(-5,5)\n",
    "C = []\n",
    "score = []\n",
    "for i in cpow:\n",
    "    C.append(10 ** i)\n",
    "for c in C:\n",
    "    start_time = datetime.datetime.now()\n",
    "    clf = LogisticRegression(penalty='l2', solver = 'lbfgs', C = c)\n",
    "    res = np.mean(cross_val_score(clf, X, y, cv = kf, scoring = 'roc_auc'))\n",
    "    score.append(res)\n",
    "    print('При C = ' + str(c) + ' качество = ' + str(res) + ', затраченное время: ' + str(datetime.datetime.now() - start_time))\n",
    "maxscore = max(score)\n",
    "maxscorei = score.index(maxscore)\n",
    "print('Лучший результат: ' + str(maxscore) + ' при С = ' + str(C[maxscorei]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После удаления категориальных признаков качество работы алгоритма незначительно увеличилось(на ~0.00006). Это связано с тем, что алгоритм считает категориальные признаки как числовые."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. На предыдущем шаге мы исключили из выборки признаки rM_hero и dM_hero, которые показывают, какие именно герои играли за каждую команду. Это важные признаки — герои имеют разные характеристики, и некоторые из них выигрывают чаще, чем другие. Выясните из данных, сколько различных идентификаторов героев существует в данной игре (вам может пригодиться фукнция unique или value_counts).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В игре 112 героев\n"
     ]
    }
   ],
   "source": [
    "heroes = pd.read_csv('./dictionaries/heroes.csv')\n",
    "heroes_N = len(heroes)\n",
    "print('В игре ' + str(heroes_num) + ' героев')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Воспользуемся подходом \"мешок слов\" для кодирования информации о героях. Пусть всего в игре имеет N различных героев. Сформируем N признаков, при этом i-й будет равен нулю, если i-й герой не участвовал в матче; единице, если i-й герой играл за команду Radiant; минус единице, если i-й герой играл за команду Dire. Ниже вы можете найти код, который выполняет данной преобразование. Добавьте полученные признаки к числовым, которые вы использовали во втором пункте данного этапа.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pick = np.zeros((features.shape[0], heroes_N))\n",
    "\n",
    "for i, match_id in enumerate(features.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, features.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, features.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "X_pick.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pick = pd.DataFrame(X_pick)\n",
    "X = pd.DataFrame(X)\n",
    "X = pd.concat([X, X_pick], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. Какое получилось качество? Улучшилось ли оно? Чем вы можете это объяснить?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "При C = 1e-05 качество = 0.7025531550961376, затраченное время: 0:00:18.903920\n",
      "При C = 0.0001 качество = 0.7308172789713854, затраченное время: 0:00:22.027931\n",
      "При C = 0.001 качество = 0.7489648358182667, затраченное время: 0:00:25.456830\n",
      "При C = 0.01 качество = 0.751877924107207, затраченное время: 0:00:31.611855\n",
      "При C = 0.1 качество = 0.7519566422623637, затраченное время: 0:01:09.888514\n",
      "При C = 1 качество = 0.7518495422486142, затраченное время: 0:01:10.129992\n",
      "При C = 10 качество = 0.751755218373682, затраченное время: 0:01:25.153004\n",
      "При C = 100 качество = 0.7517784252435108, затраченное время: 0:01:25.236894\n",
      "При C = 1000 качество = 0.7519466124448673, затраченное время: 0:01:20.615888\n",
      "При C = 10000 качество = 0.7517941462416203, затраченное время: 0:01:14.237111\n",
      "Лучший результат: 0.7519566422623637 при С = 0.1\n",
      "Худший результат: 0.7025531550961376 при С = 1e-05\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle = True) #генератор разбиений для кросс-валидации по 5 блокам\n",
    "cpow = range(-5,5)\n",
    "C = []\n",
    "score = []\n",
    "for i in cpow:\n",
    "    C.append(10 ** i)\n",
    "for c in C:\n",
    "    start_time = datetime.datetime.now()\n",
    "    clf = LogisticRegression(penalty='l2', solver = 'sag', C = c)\n",
    "    res = np.mean(cross_val_score(clf, X, y, cv = kf, scoring = 'roc_auc'))\n",
    "    score.append(res)\n",
    "    print('При C = ' + str(c) + ' качество = ' + str(res) + ', затраченное время: ' + str(datetime.datetime.now() - start_time))\n",
    "maxscore = max(score)\n",
    "maxscorei = score.index(maxscore)\n",
    "print('Лучший результат: ' + str(maxscore) + ' при С = ' + str(C[maxscorei]))\n",
    "minscore = min(score)\n",
    "minscorei = score.index(minscore)\n",
    "print('Худший результат: ' + str(minscore) + ' при С = ' + str(C[minscorei]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавление \"мешка слов\" улучшило качество алгоритма(0.7520 при С = 0.1), так как теперь информация о выбранных героях используется корректно. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Постройте предсказания вероятностей победы команды Radiant для тестовой выборки с помощью лучшей из изученных моделей (лучшей с точки зрения AUC-ROC на кросс-валидации). Убедитесь, что предсказанные вероятности адекватные — находятся на отрезке [0, 1], не совпадают между собой (т.е. что модель не получилась константной).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Apps\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "E:\\Apps\\Anaconda\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('./features_test.csv', index_col='match_id')\n",
    "X_test = test.loc[:,'start_time':'dire_first_ward_time'] \n",
    "columns = ['lobby_type','r1_hero','r2_hero','r3_hero','r4_hero','r5_hero','d1_hero','d2_hero','d3_hero','d4_hero','d5_hero']\n",
    "X_test.drop(columns, inplace=True, axis=1)\n",
    "X_test = StandardScaler().fit_transform(X_test.fillna(0)) #замена пропусков на 0 и масштабирование\n",
    "X_test_heroes = test.loc[:,columns] \n",
    "X_test_heroes.drop('lobby_type', inplace=True, axis=1) \n",
    "X_test_pick = np.zeros((test.shape[0], heroes_N))\n",
    "\n",
    "for i, match_id in enumerate(test.index):\n",
    "    for p in range(5):\n",
    "        X_test_pick[i, test.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_test_pick[i, test.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "X_test_pick.shape\n",
    "X_test_pick = pd.DataFrame(X_test_pick)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_test = pd.concat([X_test, X_test_pick], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82516202, 0.75787021, 0.18742683, ..., 0.23447281, 0.62684192,\n",
       "       0.42638481])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 0.1\n",
    "clf = LogisticRegression(penalty='l2', solver = 'sag', C = c)\n",
    "clf.fit(X, y)\n",
    "y_test = clf.predict_proba(X_test)[:, 1]\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итог"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Какое качество получилось у логистической регрессии над всеми исходными признаками? Как оно соотносится с качеством градиентного бустинга? Чем вы можете объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?**\n",
    "\n",
    "Наибольшее значение метрики AUC-ROC(0.71607) получилось при C = 0.01. Этот показатель выше чем при использовании градиентного бустинга(AUC-ROC = 0.6896). Логистическая регрессия работает в ~10 раз быстрее градиентного бустинга.\n",
    "\n",
    "**2. Как влияет на качество логистической регрессии удаление категориальных признаков (укажите новое значение метрики качества)? Чем вы можете объяснить это изменение?**\n",
    "\n",
    "После удаления категориальных признаков качество работы алгоритма незначительно увеличилось(на ~0.00006). Это связано с тем, что алгоритм считает категориальные признаки как числовые.\n",
    "\n",
    "**3. Сколько различных идентификаторов героев существует в данной игре?** В игре 112 героев.\n",
    "\n",
    "**4. Какое получилось качество при добавлении \"мешка слов\" по героям? Улучшилось ли оно по сравнению с предыдущим вариантом? Чем вы можете это объяснить?**\n",
    "\n",
    "Добавление \"мешка слов\" улучшило качество алгоритма(0.7520 при С = 0.1), так как теперь информация о выбранных героях используется корректно. \n",
    "\n",
    "**5. Какое минимальное и максимальное значение прогноза на тестовой выборке получилось у лучшего из алгоритмов?**\n",
    "\n",
    "Лучший результат: 0.7520 при С = 0.1\n",
    "Худший результат: 0.7026 при С = 1e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
